{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PEa8wamwoX1w"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "R1KeD2I-ohDw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()\n",
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FBKrQNEonJQ",
        "outputId": "6307e6df-6b90-434e-e860-edb526d79922"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqL-cXeqor9P",
        "outputId": "7d45c41f-2552-4799-a4d0-34ef0cafdae5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_aDKbX2oueh",
        "outputId": "4fae6568-6ab8-4844-b02f-039ac3801072"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DBCePfpo0H_",
        "outputId": "05029c53-ec68-4d1f-8e86-0a66d54e5872"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j4qPDkpo30v",
        "outputId": "a8bbabf3-16fc-4270-eaa2-e462cd3f2e22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buYwnBYzo5TQ",
        "outputId": "75410886-e53f-4c55-e116-13f9b85a31c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qxC25P5pKE_",
        "outputId": "0fe791c9-441f-4e7a-e476-40e1b015c310"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size = 0.33)\n",
        "N, D = X_train.shape"
      ],
      "metadata": {
        "id": "LfPzXLI3pQuP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "0gjRdzo_pZEe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the Model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(D,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "# Alternated method \n",
        "# model = tf.keras.models.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(1, input_shape=(D,), activation = 'sigmoid'))\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "#Train the Model - epochs means the time period, so we are iteratively training this model\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 300)\n",
        "\n",
        "# For logistic regression and models after it we will need gradient descent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0dg4ABeqn8c",
        "outputId": "dd3e3c12-2588-46d4-a0bc-8258e3e96fb9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.2410 - accuracy: 0.3832 - val_loss: 1.2645 - val_accuracy: 0.4202\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1297 - accuracy: 0.4147 - val_loss: 1.1537 - val_accuracy: 0.4362\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0239 - accuracy: 0.4541 - val_loss: 1.0531 - val_accuracy: 0.4681\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9272 - accuracy: 0.4987 - val_loss: 0.9627 - val_accuracy: 0.5106\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8457 - accuracy: 0.5433 - val_loss: 0.8786 - val_accuracy: 0.5372\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7689 - accuracy: 0.5879 - val_loss: 0.8050 - val_accuracy: 0.5798\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7023 - accuracy: 0.6430 - val_loss: 0.7400 - val_accuracy: 0.6117\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6850 - val_loss: 0.6821 - val_accuracy: 0.6755\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7113 - val_loss: 0.6311 - val_accuracy: 0.7021\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7349 - val_loss: 0.5869 - val_accuracy: 0.7021\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7585 - val_loss: 0.5469 - val_accuracy: 0.7181\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7927 - val_loss: 0.5103 - val_accuracy: 0.7394\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.8110 - val_loss: 0.4777 - val_accuracy: 0.7713\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8241 - val_loss: 0.4494 - val_accuracy: 0.7819\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8346 - val_loss: 0.4241 - val_accuracy: 0.8085\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8530 - val_loss: 0.4014 - val_accuracy: 0.8245\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8793 - val_loss: 0.3803 - val_accuracy: 0.8404\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8898 - val_loss: 0.3611 - val_accuracy: 0.8457\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.9003 - val_loss: 0.3438 - val_accuracy: 0.8511\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.9081 - val_loss: 0.3287 - val_accuracy: 0.8511\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.9108 - val_loss: 0.3148 - val_accuracy: 0.8777\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.9134 - val_loss: 0.3023 - val_accuracy: 0.8883\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2667 - accuracy: 0.9134 - val_loss: 0.2905 - val_accuracy: 0.8883\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9160 - val_loss: 0.2797 - val_accuracy: 0.8936\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.9186 - val_loss: 0.2705 - val_accuracy: 0.8936\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2396 - accuracy: 0.9213 - val_loss: 0.2614 - val_accuracy: 0.8936\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.9239 - val_loss: 0.2532 - val_accuracy: 0.8989\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9370 - val_loss: 0.2458 - val_accuracy: 0.8989\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2183 - accuracy: 0.9396 - val_loss: 0.2388 - val_accuracy: 0.8989\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9449 - val_loss: 0.2323 - val_accuracy: 0.9043\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.9449 - val_loss: 0.2264 - val_accuracy: 0.9096\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.9475 - val_loss: 0.2209 - val_accuracy: 0.9202\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1963 - accuracy: 0.9528 - val_loss: 0.2159 - val_accuracy: 0.9202\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1918 - accuracy: 0.9580 - val_loss: 0.2112 - val_accuracy: 0.9202\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1877 - accuracy: 0.9554 - val_loss: 0.2066 - val_accuracy: 0.9309\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9554 - val_loss: 0.2024 - val_accuracy: 0.9309\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9554 - val_loss: 0.1985 - val_accuracy: 0.9309\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1762 - accuracy: 0.9554 - val_loss: 0.1949 - val_accuracy: 0.9309\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9554 - val_loss: 0.1914 - val_accuracy: 0.9362\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9554 - val_loss: 0.1881 - val_accuracy: 0.9362\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9554 - val_loss: 0.1851 - val_accuracy: 0.9362\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1635 - accuracy: 0.9580 - val_loss: 0.1823 - val_accuracy: 0.9362\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9580 - val_loss: 0.1796 - val_accuracy: 0.9362\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9580 - val_loss: 0.1769 - val_accuracy: 0.9362\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9580 - val_loss: 0.1744 - val_accuracy: 0.9309\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9580 - val_loss: 0.1721 - val_accuracy: 0.9309\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9580 - val_loss: 0.1700 - val_accuracy: 0.9362\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9580 - val_loss: 0.1681 - val_accuracy: 0.9362\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9580 - val_loss: 0.1661 - val_accuracy: 0.9362\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9580 - val_loss: 0.1640 - val_accuracy: 0.9362\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9606 - val_loss: 0.1623 - val_accuracy: 0.9362\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9606 - val_loss: 0.1606 - val_accuracy: 0.9362\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9606 - val_loss: 0.1589 - val_accuracy: 0.9362\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9606 - val_loss: 0.1574 - val_accuracy: 0.9415\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9606 - val_loss: 0.1558 - val_accuracy: 0.9415\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9633 - val_loss: 0.1544 - val_accuracy: 0.9415\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9633 - val_loss: 0.1530 - val_accuracy: 0.9415\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 0.9633 - val_loss: 0.1517 - val_accuracy: 0.9415\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9633 - val_loss: 0.1504 - val_accuracy: 0.9415\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9606 - val_loss: 0.1492 - val_accuracy: 0.9415\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.9606 - val_loss: 0.1480 - val_accuracy: 0.9415\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9606 - val_loss: 0.1468 - val_accuracy: 0.9415\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1239 - accuracy: 0.9606 - val_loss: 0.1457 - val_accuracy: 0.9415\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9633 - val_loss: 0.1447 - val_accuracy: 0.9415\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9633 - val_loss: 0.1436 - val_accuracy: 0.9415\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9633 - val_loss: 0.1427 - val_accuracy: 0.9415\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9633 - val_loss: 0.1418 - val_accuracy: 0.9415\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9633 - val_loss: 0.1409 - val_accuracy: 0.9415\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1169 - accuracy: 0.9685 - val_loss: 0.1400 - val_accuracy: 0.9415\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9685 - val_loss: 0.1391 - val_accuracy: 0.9415\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9685 - val_loss: 0.1382 - val_accuracy: 0.9415\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9711 - val_loss: 0.1375 - val_accuracy: 0.9415\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 0.9738 - val_loss: 0.1367 - val_accuracy: 0.9415\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9738 - val_loss: 0.1360 - val_accuracy: 0.9415\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9738 - val_loss: 0.1352 - val_accuracy: 0.9415\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9738 - val_loss: 0.1345 - val_accuracy: 0.9415\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9738 - val_loss: 0.1338 - val_accuracy: 0.9468\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1081 - accuracy: 0.9738 - val_loss: 0.1331 - val_accuracy: 0.9468\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.9738 - val_loss: 0.1325 - val_accuracy: 0.9468\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9738 - val_loss: 0.1319 - val_accuracy: 0.9468\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1056 - accuracy: 0.9738 - val_loss: 0.1313 - val_accuracy: 0.9468\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9738 - val_loss: 0.1307 - val_accuracy: 0.9468\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1040 - accuracy: 0.9764 - val_loss: 0.1301 - val_accuracy: 0.9521\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9764 - val_loss: 0.1295 - val_accuracy: 0.9521\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.9764 - val_loss: 0.1290 - val_accuracy: 0.9521\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9790 - val_loss: 0.1285 - val_accuracy: 0.9521\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9790 - val_loss: 0.1280 - val_accuracy: 0.9521\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9790 - val_loss: 0.1275 - val_accuracy: 0.9521\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9790 - val_loss: 0.1271 - val_accuracy: 0.9574\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9790 - val_loss: 0.1267 - val_accuracy: 0.9574\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9790 - val_loss: 0.1262 - val_accuracy: 0.9628\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9790 - val_loss: 0.1257 - val_accuracy: 0.9628\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9790 - val_loss: 0.1253 - val_accuracy: 0.9628\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0963 - accuracy: 0.9790 - val_loss: 0.1248 - val_accuracy: 0.9628\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9790 - val_loss: 0.1244 - val_accuracy: 0.9628\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9790 - val_loss: 0.1240 - val_accuracy: 0.9628\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9790 - val_loss: 0.1237 - val_accuracy: 0.9628\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0939 - accuracy: 0.9790 - val_loss: 0.1233 - val_accuracy: 0.9628\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9790 - val_loss: 0.1229 - val_accuracy: 0.9628\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0927 - accuracy: 0.9790 - val_loss: 0.1225 - val_accuracy: 0.9628\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.9790 - val_loss: 0.1221 - val_accuracy: 0.9628\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9790 - val_loss: 0.1218 - val_accuracy: 0.9628\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9790 - val_loss: 0.1215 - val_accuracy: 0.9628\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9790 - val_loss: 0.1212 - val_accuracy: 0.9628\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9790 - val_loss: 0.1209 - val_accuracy: 0.9628\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9790 - val_loss: 0.1206 - val_accuracy: 0.9628\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9790 - val_loss: 0.1204 - val_accuracy: 0.9628\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9816 - val_loss: 0.1200 - val_accuracy: 0.9628\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9816 - val_loss: 0.1197 - val_accuracy: 0.9628\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0875 - accuracy: 0.9816 - val_loss: 0.1195 - val_accuracy: 0.9628\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.9816 - val_loss: 0.1192 - val_accuracy: 0.9628\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9816 - val_loss: 0.1189 - val_accuracy: 0.9628\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0861 - accuracy: 0.9816 - val_loss: 0.1186 - val_accuracy: 0.9628\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9816 - val_loss: 0.1184 - val_accuracy: 0.9628\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9816 - val_loss: 0.1182 - val_accuracy: 0.9628\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9816 - val_loss: 0.1180 - val_accuracy: 0.9628\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9816 - val_loss: 0.1176 - val_accuracy: 0.9628\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9816 - val_loss: 0.1175 - val_accuracy: 0.9628\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9816 - val_loss: 0.1172 - val_accuracy: 0.9628\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9816 - val_loss: 0.1169 - val_accuracy: 0.9628\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 0.9816 - val_loss: 0.1168 - val_accuracy: 0.9628\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9816 - val_loss: 0.1166 - val_accuracy: 0.9628\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9816 - val_loss: 0.1164 - val_accuracy: 0.9628\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9816 - val_loss: 0.1162 - val_accuracy: 0.9628\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9816 - val_loss: 0.1160 - val_accuracy: 0.9628\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9816 - val_loss: 0.1159 - val_accuracy: 0.9628\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9816 - val_loss: 0.1156 - val_accuracy: 0.9628\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9816 - val_loss: 0.1154 - val_accuracy: 0.9681\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9816 - val_loss: 0.1153 - val_accuracy: 0.9681\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9816 - val_loss: 0.1151 - val_accuracy: 0.9681\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9816 - val_loss: 0.1149 - val_accuracy: 0.9681\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9816 - val_loss: 0.1148 - val_accuracy: 0.9681\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9816 - val_loss: 0.1145 - val_accuracy: 0.9681\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9816 - val_loss: 0.1144 - val_accuracy: 0.9681\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9816 - val_loss: 0.1142 - val_accuracy: 0.9681\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9816 - val_loss: 0.1141 - val_accuracy: 0.9681\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9816 - val_loss: 0.1139 - val_accuracy: 0.9681\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9816 - val_loss: 0.1137 - val_accuracy: 0.9681\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9816 - val_loss: 0.1136 - val_accuracy: 0.9681\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9816 - val_loss: 0.1134 - val_accuracy: 0.9681\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9843 - val_loss: 0.1133 - val_accuracy: 0.9681\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9843 - val_loss: 0.1132 - val_accuracy: 0.9681\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9843 - val_loss: 0.1131 - val_accuracy: 0.9681\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9843 - val_loss: 0.1130 - val_accuracy: 0.9681\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9843 - val_loss: 0.1128 - val_accuracy: 0.9681\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9843 - val_loss: 0.1127 - val_accuracy: 0.9681\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9843 - val_loss: 0.1126 - val_accuracy: 0.9681\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9843 - val_loss: 0.1124 - val_accuracy: 0.9681\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9843 - val_loss: 0.1123 - val_accuracy: 0.9681\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9843 - val_loss: 0.1122 - val_accuracy: 0.9681\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9843 - val_loss: 0.1121 - val_accuracy: 0.9681\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9843 - val_loss: 0.1120 - val_accuracy: 0.9681\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9843 - val_loss: 0.1118 - val_accuracy: 0.9681\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9843 - val_loss: 0.1118 - val_accuracy: 0.9681\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9843 - val_loss: 0.1117 - val_accuracy: 0.9681\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9843 - val_loss: 0.1116 - val_accuracy: 0.9681\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9843 - val_loss: 0.1115 - val_accuracy: 0.9681\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9843 - val_loss: 0.1114 - val_accuracy: 0.9681\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9843 - val_loss: 0.1113 - val_accuracy: 0.9681\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.9843 - val_loss: 0.1111 - val_accuracy: 0.9681\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9843 - val_loss: 0.1110 - val_accuracy: 0.9681\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9843 - val_loss: 0.1109 - val_accuracy: 0.9681\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9843 - val_loss: 0.1109 - val_accuracy: 0.9681\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9843 - val_loss: 0.1107 - val_accuracy: 0.9681\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9843 - val_loss: 0.1106 - val_accuracy: 0.9681\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9843 - val_loss: 0.1106 - val_accuracy: 0.9681\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9843 - val_loss: 0.1106 - val_accuracy: 0.9681\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9843 - val_loss: 0.1104 - val_accuracy: 0.9681\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9843 - val_loss: 0.1104 - val_accuracy: 0.9681\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9843 - val_loss: 0.1103 - val_accuracy: 0.9681\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9843 - val_loss: 0.1102 - val_accuracy: 0.9681\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9843 - val_loss: 0.1101 - val_accuracy: 0.9681\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9843 - val_loss: 0.1101 - val_accuracy: 0.9681\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9843 - val_loss: 0.1100 - val_accuracy: 0.9681\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9843 - val_loss: 0.1099 - val_accuracy: 0.9681\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9843 - val_loss: 0.1098 - val_accuracy: 0.9681\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9843 - val_loss: 0.1097 - val_accuracy: 0.9681\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9843 - val_loss: 0.1097 - val_accuracy: 0.9681\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9843 - val_loss: 0.1096 - val_accuracy: 0.9681\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9843 - val_loss: 0.1095 - val_accuracy: 0.9681\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9843 - val_loss: 0.1094 - val_accuracy: 0.9681\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9843 - val_loss: 0.1093 - val_accuracy: 0.9681\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9843 - val_loss: 0.1093 - val_accuracy: 0.9681\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9843 - val_loss: 0.1093 - val_accuracy: 0.9681\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9843 - val_loss: 0.1092 - val_accuracy: 0.9681\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.9843 - val_loss: 0.1091 - val_accuracy: 0.9681\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9843 - val_loss: 0.1091 - val_accuracy: 0.9681\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9843 - val_loss: 0.1091 - val_accuracy: 0.9681\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9843 - val_loss: 0.1090 - val_accuracy: 0.9681\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0626 - accuracy: 0.9843 - val_loss: 0.1089 - val_accuracy: 0.9681\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9843 - val_loss: 0.1089 - val_accuracy: 0.9681\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9843 - val_loss: 0.1087 - val_accuracy: 0.9681\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9843 - val_loss: 0.1087 - val_accuracy: 0.9681\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9843 - val_loss: 0.1087 - val_accuracy: 0.9681\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9843 - val_loss: 0.1087 - val_accuracy: 0.9681\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9843 - val_loss: 0.1087 - val_accuracy: 0.9681\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9843 - val_loss: 0.1085 - val_accuracy: 0.9681\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9843 - val_loss: 0.1085 - val_accuracy: 0.9681\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9843 - val_loss: 0.1084 - val_accuracy: 0.9681\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9843 - val_loss: 0.1084 - val_accuracy: 0.9681\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9843 - val_loss: 0.1084 - val_accuracy: 0.9681\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9843 - val_loss: 0.1084 - val_accuracy: 0.9681\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9843 - val_loss: 0.1083 - val_accuracy: 0.9681\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9843 - val_loss: 0.1082 - val_accuracy: 0.9681\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9843 - val_loss: 0.1082 - val_accuracy: 0.9681\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9843 - val_loss: 0.1082 - val_accuracy: 0.9681\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9843 - val_loss: 0.1081 - val_accuracy: 0.9681\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9843 - val_loss: 0.1081 - val_accuracy: 0.9628\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9843 - val_loss: 0.1081 - val_accuracy: 0.9628\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9843 - val_loss: 0.1081 - val_accuracy: 0.9628\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9843 - val_loss: 0.1080 - val_accuracy: 0.9628\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9843 - val_loss: 0.1079 - val_accuracy: 0.9628\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9843 - val_loss: 0.1079 - val_accuracy: 0.9628\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9843 - val_loss: 0.1080 - val_accuracy: 0.9628\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9843 - val_loss: 0.1079 - val_accuracy: 0.9628\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9843 - val_loss: 0.1079 - val_accuracy: 0.9628\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9843 - val_loss: 0.1078 - val_accuracy: 0.9628\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9843 - val_loss: 0.1077 - val_accuracy: 0.9628\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9843 - val_loss: 0.1077 - val_accuracy: 0.9628\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9843 - val_loss: 0.1078 - val_accuracy: 0.9628\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9843 - val_loss: 0.1077 - val_accuracy: 0.9628\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9843 - val_loss: 0.1077 - val_accuracy: 0.9628\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9843 - val_loss: 0.1075 - val_accuracy: 0.9628\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9843 - val_loss: 0.1075 - val_accuracy: 0.9628\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9843 - val_loss: 0.1076 - val_accuracy: 0.9628\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9843 - val_loss: 0.1076 - val_accuracy: 0.9628\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9843 - val_loss: 0.1075 - val_accuracy: 0.9628\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.9843 - val_loss: 0.1075 - val_accuracy: 0.9628\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9869 - val_loss: 0.1074 - val_accuracy: 0.9628\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9869 - val_loss: 0.1075 - val_accuracy: 0.9628\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9869 - val_loss: 0.1074 - val_accuracy: 0.9628\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9869 - val_loss: 0.1074 - val_accuracy: 0.9628\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9869 - val_loss: 0.1073 - val_accuracy: 0.9628\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9869 - val_loss: 0.1073 - val_accuracy: 0.9628\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9869 - val_loss: 0.1072 - val_accuracy: 0.9628\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9869 - val_loss: 0.1073 - val_accuracy: 0.9628\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9869 - val_loss: 0.1072 - val_accuracy: 0.9628\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9869 - val_loss: 0.1071 - val_accuracy: 0.9628\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9869 - val_loss: 0.1071 - val_accuracy: 0.9628\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9869 - val_loss: 0.1071 - val_accuracy: 0.9628\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9869 - val_loss: 0.1069 - val_accuracy: 0.9628\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9869 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9869 - val_loss: 0.1069 - val_accuracy: 0.9628\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9869 - val_loss: 0.1069 - val_accuracy: 0.9628\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9869 - val_loss: 0.1069 - val_accuracy: 0.9628\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9869 - val_loss: 0.1069 - val_accuracy: 0.9628\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9869 - val_loss: 0.1068 - val_accuracy: 0.9628\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9869 - val_loss: 0.1069 - val_accuracy: 0.9628\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9628\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9869 - val_loss: 0.1068 - val_accuracy: 0.9628\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9869 - val_loss: 0.1068 - val_accuracy: 0.9628\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9869 - val_loss: 0.1068 - val_accuracy: 0.9628\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9628\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9628\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9628\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9628\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9628\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9628\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9628\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9628\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9628\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9628\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9628\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9869 - val_loss: 0.1064 - val_accuracy: 0.9574\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9869 - val_loss: 0.1064 - val_accuracy: 0.9574\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9869 - val_loss: 0.1064 - val_accuracy: 0.9574\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9895 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9895 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9895 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9895 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9895 - val_loss: 0.1065 - val_accuracy: 0.9574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the Model - evaluate() returns loss and accuracy\n",
        "print(\"Train Score: \", model.evaluate(X_train, y_train))\n",
        "print(\"Test Score: \", model.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtyedoBdrEMT",
        "outputId": "c2250dae-2f8f-44fd-80aa-dea56165db3b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9895\n",
            "Train Score:  [0.04646306857466698, 0.9895012974739075]\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9574\n",
            "Test Score:  [0.10645312815904617, 0.957446813583374]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the return \n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['loss'],label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "tXV5DKz5snrp",
        "outputId": "1b8206bf-2a41-4ecb-a747-b075cd4f97cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f40dbb89590>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting accuracy\n",
        "plt.plot(r.history['accuracy'], label = 'accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='val_accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "4NpEA3E4tXrC",
        "outputId": "56a6cb15-6f61-46f0-c08d-f5c403cfd24b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f40dbbcba90>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAezUlEQVR4nO3deXQd5Znn8e+jfbVly7KNdxubxSxhcQjZCQwEzBkcQjJj0lnopMNJJ9DJJJkZ6CQkQ8500t1JetIJTQ4BOiSdDls2p8e0my1DupvFgmbxgm1hDJYXSbYka1+u9MwfVTIXWcu1fKVS1f19ztHxvW+Vbj1F2T/e+9bymrsjIiLxlxd1ASIikh0KdBGRhFCgi4gkhAJdRCQhFOgiIglRENWG58yZ48uWLYtq8yIisfTss88ecveakZZFFujLli2jtrY2qs2LiMSSmb022jINuYiIJIQCXUQkIcYNdDO728wazWzLKMvNzP7WzOrM7EUzOy/7ZYqIyHgy6aH/BLh8jOVXAKvCn+uB20+8LBEROV7jBrq7PwE0j7HKOuCnHngKqDKzk7JVoIiIZCYbY+gLgb1p7+vDtmOY2fVmVmtmtU1NTVnYtIiIDJnSk6Lufoe7r3H3NTU1I15GKSIiE5SN69D3AYvT3i8K20REclp33wA/f/o12rr739R+yenzeMviqqxvLxuBvgG4wczuBd4GHHH3A1n4XBGJmW3727jzX3fTP6B5FgB2HGxjZ0MHZm9unzujJJpAN7NfABcBc8ysHvg6UAjg7j8CNgJrgTqgC/jjrFcpcoJaOvu4ZcNWXjvcGXUpibaroYOCfKOmojjqUqaFooI8fvzxNVy6et6UbG/cQHf3a8dZ7sDnslaRRKY3NUBHTyqrn+nA7b9/hQefrWcwwtmxelODALzj5GpsnHVl4laeNZ+bLj+NuTNKoi4lJ0X2LBeZHvY2d9HY3kNjWy9f++0WDnX0Tcp2rjz7JOZWRtdryzPjqrcsmJSvuSLThQI9gQYHnUe2N9A2Tm97X0s3P3hsF6nBoOe8Yk45N1686pjxvhO1tLqc956iq5pEJpsCPWE6e1N84b7neXhbQ0brv/eUGj75ruXkGZy7ZBYVxforIRJX+tebAK1dffz1ph20dvfz8oE2Xj3UyVevPJ33nzF/zN/LyzMWzCzBst0ln2ypPqi9Czoao64k3k69AhZfEHUVkkUK9AT49kMv88Cz9SyrLqOkMJ+7rnsr7zt1btRlTZ6n/g4e+TrkFUZdSXz5AGy+C258Fio0HJYUCvQIuTuHOvpwwqs/HH765Gvc8+QeBsNx7eqKYr71wbNYNa8CgE1bG/ibh3fS2z9w9HM6+wb49LuX85UrV2e/yEe/Ca88lv3PPRGN2+HUtXDtL6KuJL6adsDt74A7L4ayOVFXE0+V8+GdX4Bn7oD3/wVUTs2liWNRoE/QoY5eSgvzKR9lzLm1q4+dDR2j/v6gO7c9Xscfdh06Ztllq+exZHYZAI9sb+CP7nz6TcsvXDGbMxfMPPq+qqyQT75r+UR2Y3SDA7BzE/zhO7DwfCidnd3PPxGnXgGXfTPqKuKt5lS46gew5VdRVxJTHvz72PUwDPZDXgGs/evMf72gBAqKsl6VeUTXBq9Zs8bjOgXdka5+Lvne7ykpzOezF62kIO/NY9C9qQG+/+iucS8BLMw3PnvRSmrSLudbUFXC+06de3Rc+0hXP/+89cDRO+9mlhay9qyTyM+bxHHvVC/cdSkceAGqV8KfPjkpf/lEYu2hm+Dp22HuGdC49fh+98rvwVs/NaHNmtmz7r5mpGXqoU/Adx/eQXNnH7PLi/nzX7804jpLq8v49gfPprQof9TPWTSrlKXV5WNua2ZZIf/1rUtOqN4xNW6HQ7ve3PbqE0GYv/tLcN4nFOYiI/lPX4cV74UVF8FLD0BPW+a/O0knoxXox2nr/iP8w1Ov8bELl3Lz2tM53DlyL7ymopiigmk+w1/jdvjRu2BwhOvVz7gaLrll6msSiYvC0mD4D+C8j0dbS0iBfhxau/q46ZcvMausiC9eeiolhfksrCqNuqzxDaTgyR9A6943t7/+FBRVwEd/GYzpDTGDmtOntkYROWEK9Az09A/w8bue4bnXW8gz4wcfOZeZZTG6ZO7Zv4dHvhGc2LS0bw15BXDld2HRiMNxIhIzCvQM/PiJ3Tyzp5mPXbiUa85fxDmT8TyQ7f8Ej9468vDHiWrbB8veDZ/4HVm/r19Epg0F+jjur93L9x/dxdqz5vPND5w59soDKWgf4VHwFfOCE4vucKT+2OX93fC7P4OSKlhwbnYKT7f07fCe/6EwF0k4BfoYOntTfOXXL/HWZbP59jVnj73y4AD8/RVQ/8yxy+afDZ9+DH7zWXjp/pF/3/Lg47+F+WedeOEikpMU6GN47vUW+gecz1x0MjNKRhgz3/88HAwvW2zYEoT5u78Es9Ju8jlSD//v2/DAdfDyP8G5H4PFbzv2s+aerjAXkROiQB/D5lebyTM4b8kIY+aDg/DzD0Fn0xttKy+Fi7/25qENd2jcBts3BFeOrP0OFOrh/yKSfQr0MTyzp5nVC2ZQOWLv/LkgzNd+B065PGibsfDYcWoz+PA9wYnJirlQoKm5RGRyKNBH8ci2Bp57rZWPvX3pyCvs3BSMe595DZSN85yTvDyoWpz9IkVE0ijQh3F37vzDq/zFQ9s5c8FMPvPek9+8wj+uD8bKe9th0QXjh7mIyBRRoKfpSw3ytd9s4b7avaw9az7f/fA5b34WS/OrsPOh4NkN1SvhrA9HVaqIyDEU6EBzZx9/9c8v8/zeVl4+2M4N71vJFy89hbzhTzTc9S/Bn1d+D6pPPvaDREQilPOBvquhnU/es5mGtl5Om1/J99efw7pzFo688s5NQc9cYS4i01BGgW5mlwPfB/KBO93928OWLwXuBmqAZuCj7j7CLZHTy6GOXq65/d8pKsjnvusv5Nwls0ZfuWEr7P49vOPGKatPROR4jPt8VzPLB24DrgBWA9ea2fC5zr4D/NTdzwZuBb6V7UInwwO19bT1pPiHP7lg7DB3h4f+J5TMgHd+fuoKFBE5Dpk8sPsCoM7dd7t7H3AvsG7YOquBoYknHx9h+bQzOOjct/l1Llg+m9Pmzxh75W2/gT1/gIu/qqtaRGTaymTIZSGQ/iDtemD4vesvAB8kGJa5Gqg0s2p3P5y+kpldD1wPsGTJJM7Ck4EX6lvZc7iLGy9eNfIKPW3wk7XBJBCDKZh3Fpz/x1NbpIjIccjWSdEvAz80s+uAJ4B9wMDwldz9DuAOCOYUzdK2J+TR7Y3k5xmXnD73zQta9gTPX3nxfji4Bd7+OSgsg3M+AnmjTycnIhK1TAJ9H5B+m+OisO0od99P0EPHzCqAa9y9NVtFToZHX27k/KWzqCpLmy/z4Ba446JgFm8IppV6//+OpD4RkeOVSaBvBlaZ2XKCIF8PfCR9BTObAzS7+yBwM8EVL9PW/tZuth9o48/XnhY0uMPmO+G5n0JxJVxzZ9Arn6SJXEVEJsO4ge7uKTO7AdhEcNni3e6+1cxuBWrdfQNwEfAtM3OCIZfPTWLNJ+yxlxsBuPi0eUHDwRdh45eDeTWv+iGsvCTC6kREJiajMXR33whsHNZ2S9rrB4EHs1va5Hl0ewNLq8s4uaY8aNgZ3gH6hZeCJyKKiMRQJpctJkp33wD//sphLj5tLjb0qNtdm2DBeQpzEYm1nAv0lw+20Zsa5O0rqoOG7laor4VVl0VbmIjICcq5QN/X2g3AkuqyoKHlVcA1/ZuIxF7OBfr+MNAXVJUGDUfCR87MXBRRRSIi2ZGDgd5DZUnBG5M+Hw10zSgkIvGWc4Fe39LNwqHeOQSBXlCqZ7SISOzlXKDvb+1+Y7gF4MjeYLhl+OTOIiIxk3OBvq91hB66xs9FJAFyKtA7elMc6e4f1kNXoItIMuTUFHRvXOFSEjy/Zffj0NGgE6Iikgg51UOva+wA4OSaCtj2W/jZ1cGCeWdEWJWISHbkVA99x8F28gxWzsqD+78K886EP3oAZiyIujQRkROWU4G+q7GdJbPLKHn6h8HVLVf/SGEuIomRU0MuOw62c/6cFPzb/4Ezr4Fl74q6JBGRrMmZQO9NDbDncBfvLtkNqR5422eiLklEJKtyJtB3NXQwMOiczqtg+XoYl4gkTs4E+hO7mgBY1rcLak6FwtJxfkNEJF5yJtAf297IWQtnUty0BU56S9TliIhkXU4EenNnH8+93sJ/XpEHHQcV6CKSSDkR6E++cphBh4urDgQNCnQRSaCcCPTNe5opLcxneV8dYDohKiKJlDOBfu6SKvIbXoTqlVBcGXVJIiJZl/hAb+/pZ/uBNt66bDYceEHDLSKSWIkP9Bf2HmHQ4cL5Htzur0AXkYTKKNDN7HIz22FmdWZ20wjLl5jZ42b2H2b2opmtzX6pE7OjoR2A0wsPBg16sqKIJNS4gW5m+cBtwBXAauBaM1s9bLWvAve7+7nAeuDvsl3oRO1qaKe6vIiq3jDQq5ZGW5CIyCTJpId+AVDn7rvdvQ+4F1g3bB0HZoSvZwL7s1fiidnR0M6qeRXBcAvAzIXRFiQiMkkyCfSFwN609/VhW7pvAB81s3pgI3DjSB9kZtebWa2Z1TY1NU2g3OPj7uxq6OCUeZXBVHNlc3TLv4gkVrZOil4L/MTdFwFrgZ+Z2TGf7e53uPsad19TU1OTpU2Pbv+RHjp6U28EuuYOFZEEyyTQ9wHpk24uCtvSfQq4H8DdnwRKgDnZKPBE7G4KppxbObdCgS4iiZdJoG8GVpnZcjMrIjjpuWHYOq8DlwCY2ekEgT75YyrjaGrvBWBeZXEwhq7JoEUkwcYNdHdPATcAm4DtBFezbDWzW83sqnC1LwGfNrMXgF8A17m7T1bRmRoK9JqiXujrUA9dRBItozlF3X0jwcnO9LZb0l5vA96Z3dJO3KGOXkoK8yjvqg8aFOgikmCJvlO0qb2XORXF2GtPBg0nnR1tQSIikyjRgX6oo4+aymLYtQmqV8HsFVGXJCIyaRIe6L0sLBuEPf8Kp7w/6nJERCZVogO9qb2Xc/J3w0AfnPy+qMsREZlUiQ301MAgzV19LMxrCRr0DBcRSbjEBnpzZx/uMNdag4aKedEWJCIyyRIb6E0dwTXo1d4MhWWapUhEEi+xgd4Y3lRUmWoOeudmEVckIjK5Ehvo9c1dAFT2H4bK+RFXIyIy+RIb6HtbuikuyKOwu1Hj5yKSExIb6K8f7mLRrFKsvUE9dBHJCckN9OYuVlYZ9LWrhy4iOSGRge7u7G3uYnVld9CgHrqI5ICMnrYYN61d/bT3plhREga6eugikgMS2UN/PbzCZXl+OMfGrGXRFSMiMkUSGeh7W4JAn5+qh7wCqFoScUUiIpMvkYFe3xIMtczsej14hkt+YcQViYhMvoQGehdVZYUUtr4K1SujLkdEZEokNNC7WVRVAs2vKNBFJGckNtDPrOyC/i6o1ixFIpIbEhfo7k59SxdnFjcGDbNPjrYgEZEpkrhAP9zZR0//IKewJ2iYd2ak9YiITJXEBfrQFS6Le3ZB5QKoqIm4IhGRqZFRoJvZ5Wa2w8zqzOymEZb/jZk9H/7sNBuaJmjq1YfXoM9u3w4nvSWqMkREpty4t/6bWT5wG3ApUA9sNrMN7r5taB13/29p698InDsJtWakvqWbUnooaqmDs6+JqgwRkSmXSQ/9AqDO3Xe7ex9wL7BujPWvBX6RjeImouvgTn5V8k0MVw9dRHJKJoG+ENib9r4+bDuGmS0FlgOPnXhpE1PV8Ayn8yqccTUsf09UZYiITLlsnxRdDzzo7gMjLTSz682s1sxqm5qasrzpQEHHfgYx+OCPobhiUrYhIjIdZRLo+4DFae8XhW0jWc8Ywy3ufoe7r3H3NTU12b/6xN2p6DlAR+EcPb9FRHJOJoG+GVhlZsvNrIggtDcMX8nMTgNmAU9mt8TMHeroY54foqdsQVQliIhEZtxAd/cUcAOwCdgO3O/uW83sVjO7Km3V9cC97u6TU+r46lu6WGCH8BkjDvGLiCRaRjMWuftGYOOwtluGvf9G9sqamP0tXay2Zjpm6/nnIpJ7EnWnaFdrA8XWT5ECXURyUKICfbDldQBKapZGXImIyNRLVKDTth+AwlmLx1lRRCR5EhXog93hI2RKqqItREQkAokK9IGejuBFkW4oEpHck6hApzcMdN0hKiI5KFmB3t/BAPmQXxR1JSIiUy5RgZ7f30lvfhmYRV2KiMiUS0ygpwYGKRjoIpVfFnUpIiKRSEygH+nup5weBgrLoy5FRCQSiQn0lq4g0ClSoItIbkpMoLd29VFuPVBUGXUpIiKRSEygBz30bvJKFOgikpsSE+hDY+j5JboGXURyU2ICvaOnn3LroaB0RtSliIhEIjGB3t6TopweCkvVQxeR3JTRBBdx0NnTQ4n1Q4l66CKSmxLTQ+/tag9e6LJFEclRiQn0VPdQoGvIRURyU3ICvacteKEeuojkqMQEug89C71Y16GLSG5KTKAPDj0LXT10EclRiQl069VsRSKS2xIT6Pmp8KSohlxEJEdlFOhmdrmZ7TCzOjO7aZR1/ouZbTOzrWb2j9ktc2yDg86MVHPwpmLeVG5aRGTaGPfGIjPLB24DLgXqgc1mtsHdt6Wtswq4GXinu7eY2dzJKngkXf0D1NBKX34ZRZpPVERyVCY99AuAOnff7e59wL3AumHrfBq4zd1bANy9Mbtljq29p5+51kJPcc1UblZEZFrJJNAXAnvT3teHbelOAU4xs38zs6fM7PKRPsjMrjezWjOrbWpqmljFI+joSTHXWukrVaCLSO7K1knRAmAVcBFwLfBjM6savpK73+Hua9x9TU1N9sK3rSdFDa0MlGv8XERyVyaBvg9YnPZ+UdiWrh7Y4O797v4qsJMg4KdER2/QQ9cJURHJZZkE+mZglZktN7MiYD2wYdg6vyHonWNmcwiGYHZnsc4xdbW3UmE95FXOn6pNiohMO+MGurungBuATcB24H5332pmt5rZVeFqm4DDZrYNeBz47+5+eLKKHm7gyAEACqpOmqpNiohMOxk9D93dNwIbh7XdkvbagS+GP1Mu1XYQgNLZC6LYvIjItJCMO0U7gkAvrlKgi0juSkSgW2cwumMVU3o/k4jItJKIQM/raQlelBxzpaSISM5IRKAX9LXQaeWQn5gpUkVEjlsiAr24r43OfE0OLSK5LRGBXpo6Qk/hzKjLEBGJVCICvXywjX4FuojkuNgHem9qgJneTqp4VtSliIhEKvaBfqS7n1nWgZfOjroUEZFIxT/QO7qZYV1YmXroIpLbYh/oHUcOAZBfXh1xJSIi0Yp9oHe1BhNlFFUq0EUkt8U+0HvbgkAvmaHZikQkt8U+0FMdwXNcyqrmRFyJiEi0Yh/og53NAJTN1IO5RCS3xT7QCzqDyS3yZmhyCxHJbbEP9LLuAzRbFRSWRF2KiEikYh/oFb0HOZSv4RYRkdgH+qz+Bo4UzYu6DBGRyMU70N2ZM9BEZ/H8qCsREYlcvAO9u4VSeukp11yiIiKxDvSBltcB6K9QoIuIxDrQu5teA2BwxqKIKxERiV6sA72npR6AgqqFEVciIhK9jALdzC43sx1mVmdmN42w/DozazKz58OfP8l+qcfqD5/jUlal57iIiBSMt4KZ5QO3AZcC9cBmM9vg7tuGrXqfu98wCTWOKtXZTJuXMqO8fCo3KyIyLWXSQ78AqHP33e7eB9wLrJvcsjLU1UyrV1BVVhh1JSIikcsk0BcCe9Pe14dtw11jZi+a2YNmtnikDzKz682s1sxqm5qaJlDusM/raaGVCqpKFegiItk6Kfo7YJm7nw08DNwz0krufoe7r3H3NTU1Jz7uXdDTQqtXMFOBLiKSUaDvA9J73IvCtqPc/bC794Zv7wTOz055Yyvqb6UjbwYF+bG+WEdEJCsyScLNwCozW25mRcB6YEP6CmaW/uzaq4Dt2StxdCX9bXQVzJyKTYmITHvjXuXi7ikzuwHYBOQDd7v7VjO7Fah19w3An5nZVUAKaAaum8SaA4MDlAx20FeqQBcRgQwCHcDdNwIbh7Xdkvb6ZuDm7JY2ju5W8nBSRVVTulkRkekqvoPP3cHUc4OlsyIuRERkeohvoHcFge6lsyMuRERkeohtoHvYQ88vV6CLiECMA7237RAAhRXVEVciIjI9xDbQe440AlAyQ/OJiohAjAM9deQA3V5E2QydFBURgRgHurcfpNGrqCoriroUEZFpIbaBntfRQCMKdBGRIbEN9ILuRhq9Sg/mEhEJxTbQS3qaaPRZzCpXoIuIQFwDva+T4oFOjuTPprggP+pqRESmhXgGevtBALqK50RciIjI9BHPQO9oAKCvRJNDi4gMiWeghz30VPm8iAsREZk+4hnobfsBsMr5ERciIjJ9xDPQG7bS5DMprtSQi4jIkFgG+uD+59kyuIxZFcVRlyIiMm3EL9D7e7BDO9jiy6ku112iIiJD4hfojVsxHwh66Ap0EZGj4hfoB14AYKsvZ7YCXUTkqPgFetVSXlv8Aep9jgJdRCRNQdQFHLeVl/DIwRWwaxuz9aRFEZGj4tdDB5raeynMN6rK9GAuEZEhGQW6mV1uZjvMrM7MbhpjvWvMzM1sTfZKPFZjew9zK0sws8ncjIhIrIwb6GaWD9wGXAGsBq41s9UjrFcJfB54OttFDtfY1ktNpa5BFxFJl0kP/QKgzt13u3sfcC+wboT1vgn8JdCTxfpGFPTQFegiIukyCfSFwN609/Vh21Fmdh6w2N3/71gfZGbXm1mtmdU2NTUdd7FDGtt7mTejZMK/LyKSRCd8UtTM8oDvAV8ab113v8Pd17j7mpqaiT2Hpad/gNaufvXQRUSGySTQ9wGL094vCtuGVAJnAr83sz3AhcCGyTox2tTeC6AeuojIMJkE+mZglZktN7MiYD2wYWihux9x9znuvszdlwFPAVe5e+1kFNzYHgzR18xQD11EJN24ge7uKeAGYBOwHbjf3bea2a1mdtVkFzhcY1vQQ9eQi4jIm2V0p6i7bwQ2Dmu7ZZR1LzrxskbXqCEXEZERxe5O0ZNmlnDp6nm67V9EZJjYPcvlsjPmc9kZmnpORGS42PXQRURkZAp0EZGEUKCLiCSEAl1EJCEU6CIiCaFAFxFJCAW6iEhCKNBFRBLC3D2aDZs1Aa9N8NfnAIeyWE6UtC/Tk/ZletK+wFJ3H/H545EF+okws1p3n9R5S6eK9mV60r5MT9qXsWnIRUQkIRToIiIJEddAvyPqArJI+zI9aV+mJ+3LGGI5hi4iIseKaw9dRESGUaCLiCRE7ALdzC43sx1mVmdmN0Vdz/Eysz1m9pKZPW9mtWHbbDN72Mx2hX/OirrOkZjZ3WbWaGZb0tpGrN0CfxsepxfN7LzoKj/WKPvyDTPbFx6b581sbdqym8N92WFm74+m6mOZ2WIze9zMtpnZVjP7fNgeu+Myxr7E8biUmNkzZvZCuC//K2xfbmZPhzXfZ2ZFYXtx+L4uXL5sQht299j8APnAK8AKoAh4AVgddV3HuQ97gDnD2v4KuCl8fRPwl1HXOUrt7wHOA7aMVzuwFngIMOBC4Omo689gX74BfHmEdVeHf9eKgeXh38H8qPchrO0k4LzwdSWwM6w3dsdljH2J43ExoCJ8XQg8Hf73vh9YH7b/CPjT8PVngR+Fr9cD901ku3HroV8A1Ln7bnfvA+4F1kVcUzasA+4JX98DfCDCWkbl7k8AzcOaR6t9HfBTDzwFVJnZSVNT6fhG2ZfRrAPudfded38VqCP4uxg5dz/g7s+Fr9uB7cBCYnhcxtiX0Uzn4+Lu3hG+LQx/HLgYeDBsH35cho7Xg8AlZmbHu924BfpCYG/a+3rGPuDTkQP/YmbPmtn1Yds8dz8Qvj4IzIumtAkZrfa4HqsbwqGIu9OGvmKxL+HX9HMJeoOxPi7D9gVieFzMLN/MngcagYcJvkG0unsqXCW93qP7Ei4/AlQf7zbjFuhJ8C53Pw+4Avicmb0nfaEH37lieS1pnGsP3Q6cDJwDHAC+G205mTOzCuCXwBfcvS19WdyOywj7Esvj4u4D7n4OsIjgm8Npk73NuAX6PmBx2vtFYVtsuPu+8M9G4NcEB7ph6Gtv+GdjdBUet9Fqj92xcveG8B/hIPBj3vj6Pq33xcwKCQLw5+7+q7A5lsdlpH2J63EZ4u6twOPA2wmGuArCRen1Ht2XcPlM4PDxbitugb4ZWBWeKS4iOHmwIeKaMmZm5WZWOfQauAzYQrAPnwhX+wTw22gqnJDRat8AfDy8quJC4EjaEMC0NGws+WqCYwPBvqwPr0RYDqwCnpnq+kYSjrPeBWx39++lLYrdcRltX2J6XGrMrCp8XQpcSnBO4HHgQ+Fqw4/L0PH6EPBY+M3q+ER9NngCZ4/XEpz9fgX4StT1HGftKwjOyr8AbB2qn2Cs7FFgF/AIMDvqWkep/xcEX3n7Ccb/PjVa7QRn+W8Lj9NLwJqo689gX34W1vpi+A/spLT1vxLuyw7giqjrT6vrXQTDKS8Cz4c/a+N4XMbYlzgel7OB/whr3gLcEravIPifTh3wAFActpeE7+vC5Ssmsl3d+i8ikhBxG3IREZFRKNBFRBJCgS4ikhAKdBGRhFCgi4gkhAJdRCQhFOgiIgnx/wFVUVPVRrWagwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Predictions**"
      ],
      "metadata": {
        "id": "r1fFpHapxJZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P = model.predict(X_test)\n",
        "print(P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSKHoPsHtkjf",
        "outputId": "18577eb1-b44f-46e6-9570-001298cbfcca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.99986947e-01]\n",
            " [9.92380381e-01]\n",
            " [9.99934793e-01]\n",
            " [9.84113097e-01]\n",
            " [9.99955535e-01]\n",
            " [5.92346072e-01]\n",
            " [9.88997936e-01]\n",
            " [6.97145381e-08]\n",
            " [3.18287630e-06]\n",
            " [9.99802530e-01]\n",
            " [9.99873161e-01]\n",
            " [9.93644357e-01]\n",
            " [9.99837220e-01]\n",
            " [2.38865614e-04]\n",
            " [9.99604404e-01]\n",
            " [9.99977767e-01]\n",
            " [9.98980880e-01]\n",
            " [1.08590722e-03]\n",
            " [9.99986529e-01]\n",
            " [4.90149523e-06]\n",
            " [3.63638431e-01]\n",
            " [5.45481214e-07]\n",
            " [9.94925737e-01]\n",
            " [2.88672447e-02]\n",
            " [6.03079796e-03]\n",
            " [9.99972105e-01]\n",
            " [2.45826930e-01]\n",
            " [9.97859001e-01]\n",
            " [9.99223828e-01]\n",
            " [9.93623734e-01]\n",
            " [9.30260122e-01]\n",
            " [4.93127045e-05]\n",
            " [9.99987960e-01]\n",
            " [9.47052956e-01]\n",
            " [9.65895653e-01]\n",
            " [3.57325494e-01]\n",
            " [9.99920964e-01]\n",
            " [9.00211930e-02]\n",
            " [3.22118223e-01]\n",
            " [9.99450803e-01]\n",
            " [9.99976158e-01]\n",
            " [1.15824253e-06]\n",
            " [9.98024523e-01]\n",
            " [9.99997199e-01]\n",
            " [8.25232506e-01]\n",
            " [1.83641911e-04]\n",
            " [9.98083174e-01]\n",
            " [9.99995470e-01]\n",
            " [9.94994283e-01]\n",
            " [2.34765402e-11]\n",
            " [5.91529306e-06]\n",
            " [9.99991536e-01]\n",
            " [9.60177720e-01]\n",
            " [6.19110541e-09]\n",
            " [9.97136176e-01]\n",
            " [9.28228259e-01]\n",
            " [1.26461685e-02]\n",
            " [8.17948580e-03]\n",
            " [9.61360514e-01]\n",
            " [9.50922094e-06]\n",
            " [9.99804616e-01]\n",
            " [9.95789289e-01]\n",
            " [9.99954462e-01]\n",
            " [4.91104722e-02]\n",
            " [9.99354422e-01]\n",
            " [5.61660528e-01]\n",
            " [9.99385476e-01]\n",
            " [1.59755245e-07]\n",
            " [9.99998152e-01]\n",
            " [9.99684334e-01]\n",
            " [9.99994874e-01]\n",
            " [9.96488810e-01]\n",
            " [2.61734363e-06]\n",
            " [9.99450684e-01]\n",
            " [9.98631239e-01]\n",
            " [9.85731781e-01]\n",
            " [2.17302568e-05]\n",
            " [5.48393064e-06]\n",
            " [9.99883056e-01]\n",
            " [9.55749684e-08]\n",
            " [9.99436975e-01]\n",
            " [9.57575321e-01]\n",
            " [9.99968171e-01]\n",
            " [1.44483149e-02]\n",
            " [9.94492888e-01]\n",
            " [9.83859301e-01]\n",
            " [9.96806145e-01]\n",
            " [3.10930610e-03]\n",
            " [9.99853313e-01]\n",
            " [9.99999642e-01]\n",
            " [5.14455969e-05]\n",
            " [1.40135583e-08]\n",
            " [9.99883711e-01]\n",
            " [9.99966145e-01]\n",
            " [9.84193444e-01]\n",
            " [9.99488652e-01]\n",
            " [9.99092102e-01]\n",
            " [9.83592510e-01]\n",
            " [9.99972463e-01]\n",
            " [2.41259575e-01]\n",
            " [1.32739544e-04]\n",
            " [9.99095023e-01]\n",
            " [9.81083751e-01]\n",
            " [1.83883309e-03]\n",
            " [9.99828339e-01]\n",
            " [1.63968998e-05]\n",
            " [8.51163268e-03]\n",
            " [4.84431635e-12]\n",
            " [9.91187453e-01]\n",
            " [9.99955893e-01]\n",
            " [2.52346396e-01]\n",
            " [1.56790018e-04]\n",
            " [9.97089267e-01]\n",
            " [3.02861935e-07]\n",
            " [1.00000000e+00]\n",
            " [9.99999762e-01]\n",
            " [1.67910798e-06]\n",
            " [4.64230776e-03]\n",
            " [9.03626152e-09]\n",
            " [9.96859908e-01]\n",
            " [3.96389714e-06]\n",
            " [9.41648304e-01]\n",
            " [3.44872475e-04]\n",
            " [9.99969661e-01]\n",
            " [9.99413490e-01]\n",
            " [9.99910593e-01]\n",
            " [9.99840081e-01]\n",
            " [1.15418152e-06]\n",
            " [9.99802351e-01]\n",
            " [9.81107593e-01]\n",
            " [1.26198745e-06]\n",
            " [9.99973774e-01]\n",
            " [9.99772012e-01]\n",
            " [9.97682095e-01]\n",
            " [9.99581039e-01]\n",
            " [9.99681592e-01]\n",
            " [9.99893188e-01]\n",
            " [9.93589878e-01]\n",
            " [2.07901001e-04]\n",
            " [9.96770501e-01]\n",
            " [9.91038322e-01]\n",
            " [9.99987483e-01]\n",
            " [1.03370958e-05]\n",
            " [8.85711706e-05]\n",
            " [4.88931595e-13]\n",
            " [9.93759513e-01]\n",
            " [9.98319745e-01]\n",
            " [9.99932230e-01]\n",
            " [2.92174539e-16]\n",
            " [5.12296557e-01]\n",
            " [9.99034762e-01]\n",
            " [9.87181425e-01]\n",
            " [9.99837339e-01]\n",
            " [9.99989867e-01]\n",
            " [9.92530346e-01]\n",
            " [9.99984503e-01]\n",
            " [9.98980761e-01]\n",
            " [9.87813830e-01]\n",
            " [9.18370962e-01]\n",
            " [9.93757606e-01]\n",
            " [1.33675337e-03]\n",
            " [9.55578387e-02]\n",
            " [2.57175863e-02]\n",
            " [4.50264588e-06]\n",
            " [9.63628054e-01]\n",
            " [1.49700046e-03]\n",
            " [9.99166191e-01]\n",
            " [9.99077916e-01]\n",
            " [9.81513262e-01]\n",
            " [3.02168727e-01]\n",
            " [9.02779996e-02]\n",
            " [9.93889809e-01]\n",
            " [1.41678390e-06]\n",
            " [2.35088974e-05]\n",
            " [3.42616439e-03]\n",
            " [9.96426940e-01]\n",
            " [3.48707158e-06]\n",
            " [7.17859348e-06]\n",
            " [9.92802858e-01]\n",
            " [9.99072790e-01]\n",
            " [5.39092839e-01]\n",
            " [5.79169637e-07]\n",
            " [1.04180574e-01]\n",
            " [9.99282360e-01]\n",
            " [4.30286764e-06]\n",
            " [3.23921442e-04]\n",
            " [9.99792695e-01]\n",
            " [1.20202658e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P = np.round(P).flatten()\n",
        "print(P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWnwo1iAxUuJ",
        "outputId": "311637a9-726b-4815-e3f8-0627bd2eaca3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
            " 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0.\n",
            " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.\n",
            " 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Manually calculated accuracy: ', np.mean(P == y_test))\n",
        "print(\"Evaluate Ooutput: \", model.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xzBvkxNxnNg",
        "outputId": "513ccc4e-037c-47b8-8524-a65a0ae902c8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually calculated accuracy:  0.9574468085106383\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9574\n",
            "Evaluate Ooutput:  [0.10645312815904617, 0.957446813583374]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving the Model**"
      ],
      "metadata": {
        "id": "AYWvK1atiKvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('linearclassifier.h5')"
      ],
      "metadata": {
        "id": "V0UOv9tTytd-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0jaQHb7iUoR",
        "outputId": "9c8d0d63-9f21-4d43-c055-f9607e2f8f14"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 24K\n",
            "-rw-r--r-- 1 root root  19K Sep 26 06:46 linearclassifier.h5\n",
            "drwxr-xr-x 1 root root 4.0K Sep 22 13:42 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('linearclassifier.h5')\n",
        "print(model.layers)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy-Yxi--iYB5",
        "outputId": "3760ed39-3802-4f63-e5cb-2f734f72b436"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<keras.layers.core.dense.Dense object at 0x7f40dd6ce890>]\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10645312815904617, 0.957446813583374]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTz0s3_Oi1Ip"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}